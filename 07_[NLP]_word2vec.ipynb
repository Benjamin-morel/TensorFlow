{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOf660TT7sNpWmCtL/ewyS6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Benjamin-morel/TensorFlow/blob/main/07_%5BNLP%5D_word2vec.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "\n",
        "# **Machine Learning Model: word2vec and skip-gram**\n",
        "\n",
        "| | |\n",
        "|------|------|\n",
        "| Filename | 07_[NLP]_word2vec.ipynb |\n",
        "| Author(s) | Benjamin (contact.upside830@silomails.com) |\n",
        "| Date | January 26, 2024 |\n",
        "| Aim(s) | build a word embedding space with the skip-gram method |\n",
        "| Dataset(s) | IMDb Movie Reviews dataset [[1]](https://aclanthology.org/P11-1015.pdf)|\n",
        "| Version | Python 3.10.12 - TensorFlow 2.17.1 |\n",
        "\n",
        "\n",
        "<br> **!!Read before running!!** <br>\n",
        "* **Step 1.** Fill in the inputs.\n",
        "* **Step 2.** GPU execution is recommended for training. Yet, a pre-trained model can be used by running this notebook on a CPU. Using a pre-trained model saves time, computer resources and CO2 emissions.\n",
        "* **Step 3.** Run all and read comments.\n",
        "\n",
        "---\n",
        "\n",
        "#### **Motivation**\n",
        "\n",
        "With the IMDb dataset used in code [02_classfication_text.ipynb](https://github.com/Benjamin-morel/TensorFlow/tree/main), the model is trained using a word2vec technique and model's weights are then used to construct a word embedding space.  \n",
        "\n",
        "#### **Outline**\n",
        "\n",
        "*   Input section\n",
        "*   Python librairies & display utilities\n",
        "*   Data retrieval & set generation\n",
        "*   Embedding word space construction\n",
        "*   Classification model & training\n",
        "*   Embedding space exploration\n",
        "*   References\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "IKO5J-_-Vj3U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **0. Input section**"
      ],
      "metadata": {
        "id": "an7V4rZe30MH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_features = 5000\n",
        "max_length = 20"
      ],
      "metadata": {
        "id": "JvszvjSG37h-"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "---\n",
        "\n",
        "## **1. Python librairies & display utilities**"
      ],
      "metadata": {
        "id": "iOr8jVUqvebl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 1.1. Python librairies [RUN ME]\n",
        "\n",
        "\"\"\"math\"\"\"\n",
        "import numpy as np # linear algebra\n",
        "import sklearn.metrics # scores and evaluation metrics\n",
        "\n",
        "\"\"\"file opening and pre-processing\"\"\"\n",
        "import os # miscellaneous operating system interfaces\n",
        "import pandas as pd # data manipulation tool\n",
        "from re import escape # regular expressions\n",
        "import string # string manipulation\n",
        "import shutil # operations on files\n",
        "\n",
        "\"\"\"ML models\"\"\"\n",
        "import tensorflow as tf # framework for ML/DL\n",
        "from tensorflow import keras # API used to build model in TensorFlow\n",
        "\n",
        "\"\"\"display and export\"\"\"\n",
        "import matplotlib.pyplot as plt # graphing package\n",
        "import pickle # serialization\n",
        "\n",
        "\"\"\"performances\"\"\"\n",
        "from time import time # timer\n",
        "start = time()\n",
        "device = tf.config.list_physical_devices(device_type=None)[-1][-1]"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Rc2oQxKkvr-C"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 1.2. Import Github files [RUN ME]\n",
        "\n",
        "\"\"\"clone the Github repertory TensorFlow and imports the files required (see section 3.2)\"\"\"\n",
        "def get_github_files():\n",
        "  !git clone https://github.com/Benjamin-morel/TensorFlow.git TensorFlow_duplicata\n",
        "  path_model = 'TensorFlow_duplicata/99_pre_trained_models/07_word2vec/07_word2vec.keras'\n",
        "  path_classifier = 'TensorFlow_duplicata/99_pre_trained_models/07_word2vec/07_classification_text.keras'\n",
        "  path_dictionary = 'TensorFlow_duplicata/99_pre_trained_models/07_word2vec/dictionary_embedding.pkl'\n",
        "  path_vocab = 'TensorFlow_duplicata/99_pre_trained_models/07_word2vec/vocab.pkl'\n",
        "  path_word_list = 'TensorFlow_duplicata/99_pre_trained_models/07_word2vec/word_list'\n",
        "\n",
        "  model = keras.models.load_model(path_model, custom_objects={'Word2Vec': Word2Vec})\n",
        "  classifier = keras.models.load_model(path_classifier)\n",
        "  with open(path_dictionary, 'rb') as f:\n",
        "    dictionary = pickle.load(f)\n",
        "  with open(path_vocab, 'rb') as f:\n",
        "    vocab = pickle.load(f)\n",
        "  with open(path_word_list, 'rb') as fp:\n",
        "    word_list = pickle.load(fp)\n",
        "\n",
        "  !rm -rf TensorFlow_duplicata/\n",
        "  return model, dictionary, vocab, classifier, word_list"
      ],
      "metadata": {
        "id": "hJrHq8awwNgH"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 1.3. Figure plots [RUN ME]\n",
        "\n",
        "\"\"\"plot confusion matrix and ROC curve\"\"\"\n",
        "def plot_evaluation(test_dataset, predictions, labels=[0,1]):\n",
        "  actuals = tf.concat([y for x, y in test_dataset], axis=0)\n",
        "  predicted_labels = np.round(predictions, 0)\n",
        "\n",
        "  plt.figure(figsize=(12,5))\n",
        "\n",
        "  confusion_mat = tf.math.confusion_matrix(actuals,predicted_labels) # columns = prediction labels / rows = real labels\n",
        "\n",
        "  # Subplot 1: Confusion matrix\n",
        "  plt.subplot(1,2,1, xlabel=\"Predictions\", ylabel=\"Actuals\", title=\"Confusion matrix of the test set\", xticks=[0,1], yticks=[0,1])\n",
        "  plt.imshow(confusion_mat)\n",
        "\n",
        "  for i in range(confusion_mat.shape[0]): # annotation in each cnfusion matrix cell\n",
        "      for j in range(confusion_mat.shape[1]):\n",
        "          plt.text(x=j, y=i,s=int(confusion_mat[i, j]), va='center', ha='center', size='large')\n",
        "\n",
        "  # Subplot 2: ROC curve\n",
        "  fpr, tpr, _ = sklearn.metrics.roc_curve(actuals,  predictions.ravel())\n",
        "  plt.subplot(1,2,2, xlabel=\"FPR\", ylabel=\"TPR\", title=\"ROC curve\")\n",
        "  plt.plot(fpr, tpr)\n",
        "\n",
        "  # Metrics info\n",
        "  accuracy = sklearn.metrics.accuracy_score(actuals, predicted_labels)\n",
        "  recall = sklearn.metrics.recall_score(actuals, predicted_labels)\n",
        "  F1_score = sklearn.metrics.f1_score(actuals, predicted_labels)\n",
        "\n",
        "  print(\"############################\")\n",
        "  print(\"Evaluation on the test set: \")\n",
        "  print(\"############################\")\n",
        "  print(\"Accuracy...{:.4f}\" .format(accuracy))\n",
        "  print(\"Recall.....{:.4f}\" .format(recall))\n",
        "  print(\"F1-score...{:.4f}\" .format(F1_score))\n",
        "\n",
        "  plt.show()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "CH0tm36GQlQ3"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "\n",
        "## **2. Data retrieval and set generation**"
      ],
      "metadata": {
        "id": "vTJzD6Tv4Fca"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The skip-gram method is a word embedding technique used in Word2Vec to learn vector representations of words based on their surrounding context. It works by selecting a target word and predicting its context words within a given window size.\n",
        "\n",
        ">Example: \"This horror movie was so terrifying that I screamed!\"\n",
        "\n",
        ">Window = 1<br>\n",
        ">Target word: \"terrifying\": \"This horror movie was [**so terrifying that**] I screamed!\" <br>\n",
        ">Context words: \"so\" and \"that\"\n",
        "\n",
        "With a larger window to capture more context:\n",
        "\n",
        ">Window = 3 <br>\n",
        ">Target word: \"terrifying\": \"This horror [**movie was so terrifying that I screamed**]!\" <br>\n",
        ">Context words: \"movie\", \"was\", \"so\", \"that\", \"I\" and \"screamed\"\n",
        "\n",
        "Each word is converted to an integer and passed through a neural network with a single hidden layer. The model is trained to maximize the probability of context words given the target word, often using negative sampling to improve efficiency.\n",
        "\n",
        "After training, the hidden layer weights form a word embeddings space, where words are represented by a 16-dimensional embedding vector. Skip-gram is especially useful for capturing relationships between words.\n"
      ],
      "metadata": {
        "id": "DvEtr1KoFGLk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1. Retrieve data"
      ],
      "metadata": {
        "id": "5k2EbRgE203B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The IMDb Movie Reviews is a database created for sentiment analysis in movie reviews. It contains 50,000 movie reviews. The database is extracted and placed in the folder review_dataset. The architecture of review_dataset is as follows:\n",
        "\n",
        "```markdown\n",
        "**Imdb_dataset/**\n",
        ". . . aclImdb/\n",
        ". . . . . . train/\n",
        ". . . . . . test/\n",
        ". . . . . . README\n",
        ". . . . . . imdb.vocab\n",
        ". . . . . . imdbEr.text\n",
        "```\n",
        "\n",
        "Other files are included in the folder like `README` which provides information about the dataset and how to use it. Files `imdb.vocab` and `imdbEr.txt` contain additional information about errors, URL website and specific annotations.\n",
        "\n",
        "To train the model, the labels used to classify are not required."
      ],
      "metadata": {
        "id": "CCedTxGVU898"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_data(url, batch_size):\n",
        "\n",
        "  dataset_name = \"Imdb_dataset_1\"\n",
        "  path = tf.keras.utils.get_file(dataset_name, url, extract=True)\n",
        "  path = os.path.join(path, 'aclImdb')\n",
        "  train_path = os.path.join(path, 'train')\n",
        "  test_path = os.path.join(path, 'test')\n",
        "  remove_dir = os.path.join(train_path, 'unsup') # remove the folder with unlabeled reviews for unsupervised learning\n",
        "  shutil.rmtree(remove_dir)\n",
        "\n",
        "  # data used to build embedding word space with the skip-gram method\n",
        "  data_skip_gram = tf.keras.utils.text_dataset_from_directory(train_path, labels=None, batch_size=batch_size, validation_split=None, shuffle=True, seed=1, verbose=0)\n",
        "\n",
        "  # data for classification model (same as 02_classification_text.ipynb)\n",
        "  raw_train_ds = keras.utils.text_dataset_from_directory(train_path, batch_size=32, validation_split=0.2, subset='training', shuffle=True, seed=1)\n",
        "  raw_val_ds = keras.utils.text_dataset_from_directory(train_path, batch_size=32, validation_split=0.2, subset='validation', shuffle=True, seed=1)\n",
        "  raw_test_ds = keras.utils.text_dataset_from_directory(test_path, batch_size=32)\n",
        "\n",
        "  return data_skip_gram, raw_train_ds, raw_val_ds, raw_test_ds"
      ],
      "metadata": {
        "id": "6tyDasAh_ZyY"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\"\n",
        "\n",
        "batch_size = 1\n",
        "\n",
        "all_texts, raw_train_ds, raw_val_ds, raw_test_ds = get_data(url, batch_size)"
      ],
      "metadata": {
        "id": "sVSYard4_kii",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f27382b-748b-4fcf-9ff5-241cb1b8e8b0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 25000 files belonging to 2 classes.\n",
            "Using 20000 files for training.\n",
            "Found 25000 files belonging to 2 classes.\n",
            "Using 5000 files for validation.\n",
            "Found 25000 files belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The batch size is 1 to facilitate pre-processing of texts. The variable `nb_text` is used to control the number of texts to be supplied to the model.\n",
        "\n"
      ],
      "metadata": {
        "id": "d5rIxD1iGh-q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for text in all_texts.take(1):\n",
        "  print(\"Here, an example of text data used for the skip-gram method: \\n\", text.numpy())"
      ],
      "metadata": {
        "id": "K9xSdAZOT2JD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ab3299d-96aa-4ba8-a20c-e4416bf471b7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here, an example of text data used for the skip-gram method: \n",
            " [b'\"Dressed to Kill\" is Brian DePalma\\'s best film, an absolute thrill ride of suspense, humor and style that remains unrivaled today. DePalma has a bum rap in Hollywood, as most people claim that he rips off Alfred Hitchcock. He does not. Hitchcock could only dream of what DePalma shows in his thrillers.<br /><br />Sadly, the original uncut version of \"Dressed to Kill\" is no longer available on video. The current copy released by Goodtimes is the Jack Valenti approved R rated cut. But some copies of DePalma\\'s original cut still exist. It is the one distributed by Warner Home Video, in both a green cardboard box with Angie Dickinson on the cover, or in a black clamshell case with the theatrical poster on silver lining. These are the ones to get, if you can find a copy. I have the green one and it is among my treasured possessions.<br /><br />Anyway, back to the story. Dickinson plays Kate Miller, a sexually frustrated wife who is being treated by Dr. Robert Elliott ( Michael Caine) for her obsessive fantasies. While on a trip to the museum (a real tour-de-force for DePalma in terms of camera work and suspense), <br /><br />Miller is picked up by a stranger. You can pretty much guess what happens to her, since the ads and box art give away the story. But there are a few complications. A hooker (Nancy Allen) is the sole witness to the murder. Kate Miller\\'s son Peter (Keith Gordon) is a teenage genius determined to solve the crime. And Dr. Elliott\\'s answering machine has a certain message on it...about a missing razor...<br /><br />I\\'m not spoiling the film at all for you since what I have described above takes place within the opening half hour and DePalma\\'s biggest surprises are reserved for the last hour. This film is explicit, however, enough for Valenti (head of the MPAA) to demand cuts in the film. What surprises me is what cuts he wanted. Several cuts in the opening shower scene and one or two slashing scenes and some of Nancy Allen\\'s dialogue (Valenti wanted \"cock\" changed to \"bulge\"). This is a film that is very violent and bloody, yet the objections are to sexual content. I\\'d love to hear Valenti\\'s explaination at how seeing two women in a tender love scene in \"Lost and Delirious\" is somehow more damaging to a young mind than Arnold Schwarzenegger blowing away people with a chain gun. It just isn\\'t fair.<br /><br />What makes \"Dressed to Kill\" so good is that not only are the technical credits first rate, but the performances are very good as well. Michael Caine, who was in a lot of crap in this time period, gives one of his best performances as the doctor. Angie Dickinson is better than usual, possibly because she actually has a strong role here. Nancy Allen adds this to her range of performances that has her pegged as one of the most underrated and overlooked actresses in the world. Keith Gordon is wonderful as the genius and i loved all those inventions of his.<br /><br />DePalma is one of our best directors who has never received the recognition he deserved. The recent joke of the AFI 100 Best Thrillers list showed that very few people actually know what a thriller is. If they were to actually open their eyes for once, they would see that DePalma has staked his career in thrillers and is actually the best craftsman. This is even better than \"Psycho\". It\\'s a shame that very few actually know that.<br /><br />**** out of 4 stars']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2. Pre-processing"
      ],
      "metadata": {
        "id": "bmEWej3C24FC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Input data must be processed:\n",
        "```markdown\n",
        "Tensor(['The film was ....'])\n",
        "Tensor(['I see this movie ...'])\n",
        ". . .\n",
        "```\n",
        "Each tensor is composed of a sentence (and not an entire movie review). So, for one review, several tensors can be generated. It is assumed that each sentence carries a context/meaning. A sentence is defined here as a series of words ending by a `. `, a `? ` or a ' ! `."
      ],
      "metadata": {
        "id": "t7dr6A2lWIJS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if device == \"GPU\":\n",
        "  punctuation_to_remove = escape(string.punctuation).replace('.', '').replace('?', '').replace('!', '')"
      ],
      "metadata": {
        "id": "2HK0RxBRxaKr"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The 50 most frequent words in the dataset are also removed. This list of words comes from the Jupyter Notebook [02_classfication_text.ipynb](https://github.com/Benjamin-morel/TensorFlow/tree/main). These words are removed because they carry a little meaning and increase the size of the model's input vectors:\n",
        "\n",
        "```markdown\n",
        "The dog barked loudly --> dog barked loudly --> ['dog', 'barked', 'loudly']\n",
        "```"
      ],
      "metadata": {
        "id": "Hcbf6V3WQNkC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if device == \"GPU\":\n",
        "  token_common = [' the ', ' and ', ' a ', ' of ', ' to ', ' is ', ' in ', ' it ', ' i ', ' this ', ' that ', ' br ', ' was ', ' as ', ' with ', ' for ',\n",
        "                  ' you ', ' on ', ' are ', ' one ', ' be ', ' he ', ' its ', ' have ', ' an ', ' by ', ' at ', ' all ', ' from ', ' who ', ' so ',\n",
        "                  ' they ', ' her ', ' just ', ' some ', ' out ', ' about ', ' or ', ' s ', ' if ', '  c  ', ' there ', ' were ', ' would ', ' had ', ' it ', ' we ']"
      ],
      "metadata": {
        "id": "ZCDiZgqznO3T"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_standardization_for_skip_gram(input_text):\n",
        "  text_modified = tf.strings.lower(input_text) # upper cases --> lower cases\n",
        "  text_modified = tf.strings.regex_replace(text_modified, '<br />', ' ') # remove HTML strings\n",
        "  for i in range(len(token_common)):\n",
        "    text_modified = tf.strings.regex_replace(text_modified, token_common[i], ' ') # remove frequent words\n",
        "  text_modified = tf.strings.regex_replace(text_modified, '[%s]' % punctuation_to_remove, '') # remove punctuation\n",
        "  return text_modified"
      ],
      "metadata": {
        "id": "WYbUfk3h31Ow"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if device == \"GPU\":\n",
        "  all_texts_processed = all_texts.map(lambda x: custom_standardization_for_skip_gram(x))\n",
        "  for text in all_texts_processed.take(1):\n",
        "    print(\"Here is the result of the transformation: \\n\", text.numpy())"
      ],
      "metadata": {
        "id": "wS7XzSSMxj15"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "An example of a pre-processed movie review is displayed. Only the punctuation elements `.`, `?` and `!` are retained."
      ],
      "metadata": {
        "id": "87oEZsURRan_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From these pre-processed texts, the sentences are separated and isolated into tensors."
      ],
      "metadata": {
        "id": "rQ3DJ4c6SJfA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_sentences(text):\n",
        "  text =  tf.strings.split(text, '. ')\n",
        "  text =  tf.strings.split(text, '? ')\n",
        "  text =  tf.strings.split(text, '! ')\n",
        "  return text"
      ],
      "metadata": {
        "id": "d-xpMZykxvWQ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if device == \"GPU\":\n",
        "  all_texts_processed_sentences = all_texts_processed.map(lambda x: split_sentences(x))"
      ],
      "metadata": {
        "id": "AvwZTQq5-RCB"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, the tensors contained in `train_ds` - with variable size - are converted into individual scalar tensors."
      ],
      "metadata": {
        "id": "giPPN4gmULcU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_ragged_tensor(ragged_tensor):\n",
        "  flat_values = ragged_tensor.flat_values\n",
        "  return tf.data.Dataset.from_tensor_slices(flat_values)"
      ],
      "metadata": {
        "id": "4OqamkAlyKxb"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if device == \"GPU\":\n",
        "  all_texts_processed_sentences = all_texts_processed_sentences.flat_map(split_ragged_tensor)\n",
        "  for text in all_texts_processed_sentences.take(5):\n",
        "    print(text.numpy())"
      ],
      "metadata": {
        "id": "cohL_W41-VC1"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.3. Vectorization"
      ],
      "metadata": {
        "id": "m5yFx-K027PG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A maximum of n tokens (default: 20) are generated for each sentence and then vectorized."
      ],
      "metadata": {
        "id": "gO0xPfviSlL2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectorize_layer = tf.keras.layers.TextVectorization(standardize=None, # already done\n",
        "                                                    max_tokens=max_features,\n",
        "                                                    output_mode='int',\n",
        "                                                    output_sequence_length=max_length)"
      ],
      "metadata": {
        "id": "JKsOEFqVWFBL"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if device == \"GPU\":\n",
        "  vectorize_layer.adapt(all_texts_processed_sentences.batch(batch_size=1024))\n",
        "  skip_gram_data = all_texts_processed_sentences.map(vectorize_layer)"
      ],
      "metadata": {
        "id": "PvXHQq58-fER"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if device == \"GPU\":\n",
        "  word_list = vectorize_layer.get_vocabulary()\n",
        "  int_list = list(skip_gram_data.as_numpy_iterator())\n",
        "\n",
        "  with open(\"word_list\", \"wb\") as fp:   #Pickling\n",
        "    pickle.dump(word_list, fp)\n",
        "\n",
        "  for seq in int_list[:5]:\n",
        "    print(f\"{seq} => {[word_list[i] for i in seq]}\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "mVYcxH6OznQJ"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "\n",
        "## **3. Embedding word space construction**"
      ],
      "metadata": {
        "id": "shZUw7pEXayn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1. Skip-gram pair generation"
      ],
      "metadata": {
        "id": "HPnGyRw02_lC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generates skip-gram pairs with negative sampling for a list of sequences (int-encoded sentences) based on window size, number of negative samples and vocabulary size."
      ],
      "metadata": {
        "id": "kbDFjB9AX9nR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_training_data(sequences, window_size, num_ns, vocab_size, seed):\n",
        "  targets, contexts, labels = [], [], []\n",
        "\n",
        "  sampling_table = tf.keras.preprocessing.sequence.make_sampling_table(vocab_size) # Build the sampling table for `vocab_size` tokens.\n",
        "\n",
        "  for sequence in sequences: # Iterate over all sequences (sentences) in the dataset\n",
        "\n",
        "    positive_skip_grams, _ = tf.keras.preprocessing.sequence.skipgrams(sequence,\n",
        "                                                                       vocabulary_size=vocab_size,\n",
        "                                                                       sampling_table=sampling_table,\n",
        "                                                                       window_size=window_size,\n",
        "                                                                       negative_samples=0) # Generate positive skip-gram pairs for a sequence (sentence)\n",
        "\n",
        "    for target_word, context_word in positive_skip_grams: # Iterate over each positive skip-gram pair to produce training examples with a positive context word and negative samples.\n",
        "\n",
        "      context_class = tf.expand_dims(tf.constant([context_word], dtype=\"int64\"), 1)\n",
        "\n",
        "      negative_sampling_candidates, _, _ = tf.random.log_uniform_candidate_sampler(true_classes=context_class,\n",
        "                                                                                   num_true=1,\n",
        "                                                                                   num_sampled=num_ns,\n",
        "                                                                                   unique=True,\n",
        "                                                                                   range_max=vocab_size,\n",
        "                                                                                   seed=seed,\n",
        "                                                                                   name=\"negative_sampling\")\n",
        "\n",
        "\n",
        "      context = tf.concat([tf.squeeze(context_class,1), negative_sampling_candidates], 0) # Build context and label vectors (for one target word)\n",
        "      label = tf.constant([1] + [0]*num_ns, dtype=\"int64\")\n",
        "\n",
        "      targets.append(target_word) # Append each element from the training example to global lists.\n",
        "      contexts.append(context)\n",
        "      labels.append(label)\n",
        "\n",
        "  return targets, contexts, labels"
      ],
      "metadata": {
        "id": "QA4gyGLV3qak"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if device == \"GPU\":\n",
        "  targets, contexts, labels = generate_training_data(sequences=int_list,\n",
        "                                                     window_size=2,\n",
        "                                                     num_ns=4,\n",
        "                                                     vocab_size=max_features,\n",
        "                                                     seed=1)\n",
        "\n",
        "  targets = np.array(targets)\n",
        "  contexts = np.array(contexts)\n",
        "  labels = np.array(labels)\n",
        "\n",
        "  print(f\"targets.shape: {targets.shape}\")\n",
        "  print(f\"contexts.shape: {contexts.shape}\")\n",
        "  print(f\"labels.shape: {labels.shape}\")"
      ],
      "metadata": {
        "id": "T_fLkogA3-gF"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2. Performances and batches"
      ],
      "metadata": {
        "id": "UgY7QoLBYBrf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if device == \"GPU\":\n",
        "  batch_size = 1024\n",
        "  AUTOTUNE = tf.data.AUTOTUNE\n",
        "  dataset = tf.data.Dataset.from_tensor_slices(((targets, contexts), labels))\n",
        "  dataset = dataset.shuffle(len(targets)).batch(batch_size).repeat()\n",
        "\n",
        "  dataset = dataset.cache().prefetch(buffer_size=AUTOTUNE)"
      ],
      "metadata": {
        "id": "8NoVgzD-KC-S"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.3. Model definition"
      ],
      "metadata": {
        "id": "tiVadQe9YHMm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@keras.utils.register_keras_serializable()\n",
        "class Word2Vec(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, **kwargs):\n",
        "    super(Word2Vec, self).__init__()\n",
        "    self.vocab_size = vocab_size # Store vocab_size as an attribute\n",
        "    self.embedding_dim = embedding_dim # Store embedding_dim as an attribute\n",
        "    self.target_embedding = tf.keras.layers.Embedding(vocab_size,\n",
        "                                      embedding_dim,\n",
        "                                      name=\"w2v_embedding\")\n",
        "    self.context_embedding = tf.keras.layers.Embedding(vocab_size,\n",
        "                                       embedding_dim)\n",
        "\n",
        "  def call(self, pair):\n",
        "    target, context = pair\n",
        "    # target: (batch, dummy?)  # The dummy axis doesn't exist in TF2.7+\n",
        "    # context: (batch, context)\n",
        "    if len(target.shape) == 2:\n",
        "      target = tf.squeeze(target, axis=1)\n",
        "    # target: (batch,)\n",
        "    word_emb = self.target_embedding(target)\n",
        "    # word_emb: (batch, embed)\n",
        "    context_emb = self.context_embedding(context)\n",
        "    # context_emb: (batch, context, embed)\n",
        "    dots = tf.einsum('be,bce->bc', word_emb, context_emb)\n",
        "    # dots: (batch, context)\n",
        "    return dots\n",
        "\n",
        "  def get_config(self): # Define get_config to include vocab_size and embedding_dim\n",
        "    config = super(Word2Vec, self).get_config()\n",
        "    config.update({\"vocab_size\": self.vocab_size, \"embedding_dim\": self.embedding_dim})\n",
        "    return config\n",
        "\n",
        "  @classmethod\n",
        "  def from_config(cls, config): # Define from_config to use vocab_size and embedding_dim\n",
        "      return cls(**config)"
      ],
      "metadata": {
        "id": "-Fmo3B7x4Ebi"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model(embedding_dim):\n",
        "  model = Word2Vec(max_features, embedding_dim)\n",
        "  model.compile(optimizer='adam',\n",
        "                loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
        "                metrics=None)\n",
        "  return model"
      ],
      "metadata": {
        "id": "_AUxMqyq9jq3"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.4. Training phase"
      ],
      "metadata": {
        "id": "_-D7FGkZYKg0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, training_data, steps_per_epoch, **kwargs):\n",
        "  kwargs.setdefault(\"epochs\", 15)\n",
        "  kwargs.setdefault(\"verbose\", 1)\n",
        "  log = model.fit(training_data, steps_per_epoch = steps_per_epoch, **kwargs)\n",
        "\n",
        "  return log.history[\"loss\"]"
      ],
      "metadata": {
        "id": "MmaQTLUD8bE0"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if device == \"GPU\":\n",
        "  model = create_model(16)\n",
        "  steps_per_epoch = len(targets) // batch_size\n",
        "  history = train_model(model, dataset, steps_per_epoch)\n",
        "  model.save('07_word2vec.keras')\n",
        "else:\n",
        "  model, dictionary_embedding, vocab, classifier_model, word_list = get_github_files()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WxdU_xWo-Fpk",
        "outputId": "d61007c6-86c7-4fde-d82d-53d8b1815c6b"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'TensorFlow_duplicata'...\n",
            "remote: Enumerating objects: 888, done.\u001b[K\n",
            "remote: Counting objects: 100% (190/190), done.\u001b[K\n",
            "remote: Compressing objects: 100% (54/54), done.\u001b[K\n",
            "remote: Total 888 (delta 180), reused 136 (delta 136), pack-reused 698 (from 3)\u001b[K\n",
            "Receiving objects: 100% (888/888), 194.49 MiB | 31.92 MiB/s, done.\n",
            "Resolving deltas: 100% (450/450), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "\n",
        "## **4. Classification model and training**"
      ],
      "metadata": {
        "id": "jQVDTF20a9vD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.1. Pre-processing layer for classification model"
      ],
      "metadata": {
        "id": "VXKYegYQbEmU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "weights = model.get_layer('w2v_embedding').get_weights()[0]"
      ],
      "metadata": {
        "id": "EsQnN_yhbLEs"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@keras.utils.register_keras_serializable()\n",
        "def custom_standardization_classification(input_text):\n",
        "  no_uppercase = tf.strings.lower(input_text) # upper case --> lower case letters\n",
        "  no_html_uppercase = tf.strings.regex_replace(no_uppercase, '<br />', ' ') # remove HTML strings\n",
        "  no_punctuation_html_uppercase = tf.strings.regex_replace(no_html_uppercase, '[%s]' % escape(string.punctuation), '') # remove punctuation\n",
        "  return no_punctuation_html_uppercase"
      ],
      "metadata": {
        "id": "L9ysUj4JbPOb"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_train_ds = raw_train_ds.map(lambda x, y: (custom_standardization_classification(x), y))\n",
        "raw_test_ds = raw_test_ds.map(lambda x, y: (custom_standardization_classification(x), y))\n",
        "raw_val_ds = raw_val_ds.map(lambda x, y: (custom_standardization_classification(x), y))"
      ],
      "metadata": {
        "id": "3tGceeJhbTyd"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = 500 # truncate to the 500th word\n",
        "\n",
        "vectorize_layer1 = keras.layers.TextVectorization(standardize=None,\n",
        "                                                 max_tokens=max_features,\n",
        "                                                 output_sequence_length=max_length,\n",
        "                                                 output_mode='int',\n",
        "                                                 vocabulary = word_list\n",
        "                                                 )"
      ],
      "metadata": {
        "id": "gyUkUs0AbXdC"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "raw_train_ds = raw_train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "raw_test_ds = raw_test_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "raw_val_ds = raw_val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
      ],
      "metadata": {
        "id": "7e6_fEX5bdv5"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.2. Classification model"
      ],
      "metadata": {
        "id": "MpvsmZXcbf-X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "custom_embedding_layer = keras.Sequential([keras.layers.Embedding(input_dim = max_features, output_dim = 16, embeddings_initializer=keras.initializers.Constant(weights))])"
      ],
      "metadata": {
        "id": "8sPG9_jCbj49"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "custom_embedding_layer.trainable = False"
      ],
      "metadata": {
        "id": "Pm68bjsObl6v"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_classifier():\n",
        "  embedding_dim = 16\n",
        "  model = keras.Sequential([vectorize_layer1, # pre-processing layer\n",
        "                            custom_embedding_layer,\n",
        "                            keras.layers.Dropout(0.2),\n",
        "                            keras.layers.Dense(16, activation='relu'),\n",
        "                            keras.layers.GlobalAveragePooling1D(),\n",
        "                            keras.layers.Dropout(0.2),\n",
        "                            keras.layers.Dense(1, activation='sigmoid')\n",
        "                            ], name=\"classification_text_model\")\n",
        "\n",
        "  model.compile(loss=keras.losses.BinaryCrossentropy(from_logits=False),\n",
        "                optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
        "                metrics=[tf.metrics.BinaryAccuracy(name=\"binary_accuracy\", threshold=0.5)])\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "o91K6dGRbttb"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_classifier(model, training_data, validation_data, callbacks, **kwargs):\n",
        "  kwargs.setdefault(\"epochs\", 5)\n",
        "  kwargs.setdefault(\"verbose\", 1)\n",
        "  log = model.fit(training_data, validation_data=validation_data, callbacks=callbacks, **kwargs)\n",
        "\n",
        "  return log.history[\"loss\"], log.history[\"binary_accuracy\"], log.history[\"val_loss\"], log.history[\"val_binary_accuracy\"]"
      ],
      "metadata": {
        "id": "-ShwqBsOb5Dd"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if device == \"GPU\":\n",
        "  stop_early = keras.callbacks.EarlyStopping(monitor='val_binary_accuracy',\n",
        "                                            patience=20,\n",
        "                                            restore_best_weights=True,\n",
        "                                            min_delta=0.001)"
      ],
      "metadata": {
        "id": "r03OvT0zuBxZ"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if device == \"GPU\":\n",
        "  epochs = 100\n",
        "  classifier_model = create_classifier()\n",
        "  classifier_accuracy = train_classifier(classifier_model, raw_train_ds, raw_val_ds, callbacks=stop_early, epochs=epochs)\n",
        "  print(\"Accuracy max %0.1f %% reached at the epoch %d\" %(100*max(classifier_accuracy[3]), np.argmax(classifier_accuracy[3])+1))\n",
        "  classifier_model.save('07_classification_text.keras')"
      ],
      "metadata": {
        "id": "aI4QvL6avN-T"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.3. Evaluation and predictions"
      ],
      "metadata": {
        "id": "B_NpeYlfcWR5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_predictions(dataset):\n",
        "  loss_test, accuracy_test = classifier_model.evaluate(dataset, verbose=0)\n",
        "  predictions = classifier_model.predict(dataset, verbose=0)\n",
        "  print(\"Test loss value %0.1f \\nTest accuracy: %0.1f %%\" %(loss_test, 100*accuracy_test))\n",
        "  return predictions"
      ],
      "metadata": {
        "id": "pWv3x_2tO6L4"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = get_predictions(raw_test_ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YpbdyqG2O_N6",
        "outputId": "83b16a3e-dda1-452c-e2f4-f627610633e9"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss value 0.5 \n",
            "Test accuracy: 80.2 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_evaluation(raw_test_ds, predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 591
        },
        "id": "eXDOnty4PUxd",
        "outputId": "17e7dc6a-88e3-4659-8abb-9bf4b2ac7b9b"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "############################\n",
            "Evaluation on the test set: \n",
            "############################\n",
            "Accuracy...0.8019\n",
            "Recall.....0.8890\n",
            "F1-score...0.8178\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "\n",
        "## **5. Embedding space exploration**"
      ],
      "metadata": {
        "id": "O2ayOZiwYfeN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.1. Embedding dictionary"
      ],
      "metadata": {
        "id": "h2ApzsXuYoie"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if device == \"GPU\":\n",
        "  vocab = vectorize_layer.get_vocabulary()\n",
        "  dictionary_embedding = {vocab[i]:weights[i] for i in range(len(vocab))} # build the embedding dictionary\n",
        "\n",
        "  with open('vocab.pkl', 'wb') as f:\n",
        "    pickle.dump(vocab, f)\n",
        "\n",
        "  with open('dictionary_embedding.pkl', 'wb') as f:\n",
        "    pickle.dump(dictionary_embedding, f)"
      ],
      "metadata": {
        "id": "KEAQX3iF4NDi"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dictionary_embedding[\"money\"]"
      ],
      "metadata": {
        "id": "UF-ehK1Lie7m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4bfdf8bc-bfb1-4c62-f2a1-11edd8f06279"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.4511153 , -0.1555667 , -0.16605273, -0.06758016,  0.32298324,\n",
              "       -0.34737492, -0.2298189 , -0.04030469, -0.76292896,  0.18483113,\n",
              "        0.1460447 , -0.1714578 , -0.37093538, -0.7198567 , -0.25342757,\n",
              "        0.20178515], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.2. Similarities and analogies"
      ],
      "metadata": {
        "id": "jkHFz7FSYv5R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get the distance between two elements in the embedding space\n",
        "\n",
        "def get_distance(token1, token2):\n",
        "  p1 = dictionary_embedding[token1]\n",
        "  p2 = dictionary_embedding[token2]\n",
        "  distance = np.linalg.norm(p2-p1)\n",
        "  return distance\n",
        "\n",
        "# get the cosinus similarity between two elements in the embedding space\n",
        "\n",
        "def get_cosinus_similarity(token1, token2):\n",
        "  p1 = dictionary_embedding[token1]\n",
        "  p2 = dictionary_embedding[token2]\n",
        "  dot_product = np.dot(p1, p2)\n",
        "  magnitude_1 = np.linalg.norm(p1)\n",
        "  magnitude_2 = np.linalg.norm(p2)\n",
        "  cosine_sim = dot_product / (magnitude_1 * magnitude_2)\n",
        "  return cosine_sim"
      ],
      "metadata": {
        "id": "D32RiQSyihOX"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get elements closest to a specific element in the embedding space\n",
        "\n",
        "def get_synomym(token, n, used_distance=True):\n",
        "  p1 = dictionary_embedding[token]\n",
        "  candidate_list = {} # stores n synonyms\n",
        "  for i in range(1, len(vocab)): # only the first 1000 words of the embedding dictionary are searched\n",
        "    token_candidate = vocab[i]\n",
        "    if used_distance == True: candidate_list[token_candidate] = get_distance(token, token_candidate)\n",
        "    else: candidate_list[token_candidate] = get_cosinus_similarity(token, token_candidate)\n",
        "\n",
        "  sorted_items = sorted(candidate_list.items(), key=lambda item: item[1])\n",
        "\n",
        "  if used_distance == True: synonym_list = sorted_items[1:n+1]\n",
        "  else: synonym_list = sorted_items[-(n+1):-1]\n",
        "  words = [(item[0], item[1]) for item in synonym_list]\n",
        "  return print(words)"
      ],
      "metadata": {
        "id": "FNWrbXIUiuI7"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word = \"terrible\"\n",
        "nb = 10\n",
        "get_synomym(word, nb, used_distance=False)"
      ],
      "metadata": {
        "id": "8sUp8U2FiwUP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af022c97-9026-42e5-8d2a-abcf1aac81e1"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('pointless', 0.8044394), ('ludicrous', 0.8148322), ('totally', 0.8178258), ('laughable', 0.8416559), ('appalling', 0.85137874), ('abysmal', 0.8675813), ('dreadful', 0.8718299), ('horrendous', 0.8805921), ('horrible', 0.90182066), ('awful', 0.9120636)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_analogy(vector, n):\n",
        "  candidate_list = {} # stores n synonyms\n",
        "  for i in range(1, len(vocab)):\n",
        "    token_candidate = vocab[i]\n",
        "    vector_candidate = dictionary_embedding[token_candidate]\n",
        "    candidate_list[token_candidate] = sum(abs(vector - vector_candidate))\n",
        "\n",
        "  sorted_items = sorted(candidate_list.items(), key=lambda item: item[1])\n",
        "  synonym_list = sorted_items[0:n]\n",
        "  words = [item[0] for item in synonym_list]\n",
        "  print(words)"
      ],
      "metadata": {
        "id": "FlzOsPSGRUmY"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "analogy = dictionary_embedding[\"funny\"] - dictionary_embedding[\"nice\"] + dictionary_embedding[\"terrible\"]\n",
        "get_analogy(analogy, 5)"
      ],
      "metadata": {
        "id": "TvO-QKgeRWPa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3d8cb86-de76-4474-e511-9544fbdca223"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['pointless', 'offensive', 'boring', 'depressing', 'terrible']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "\n",
        "## **6. References**\n",
        "\n",
        "| | | | | |\n",
        "|------|------|------|------|------|\n",
        "| Index | Title | Author(s) | Type | Comments |\n",
        "|[[1]](https://aclanthology.org/P11-1015.pdf) | IMDB dataset | Andrew L. Maas & al | dataset & paper | - |\n",
        "|[[2]](https://www.tensorflow.org/tutorials/keras/text_classification) | Basic text classification | TensorFlow | dataset | - |\n",
        "|[[3]](https://www.tensorflow.org/guide/data_performance) | Better performance with the tf.data API | TensorFlow | Tutoriels | - |\n",
        "|[[4]](https://www.cs.toronto.edu/~lczhang/360/lec/w05/w2v.html) | Word2Vec and GloVe Vectors | Toronto university | website | - |"
      ],
      "metadata": {
        "id": "iA4CnxdVY7OH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Notebook run in %.1f seconds on %s\" % ((time() - start), tf.config.list_physical_devices(device_type=None)[-1][-1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xgIFhnxO4bxT",
        "outputId": "b8a0e409-f3db-42f9-c85f-eb3e0f499b5b"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Notebook run in 64.0 seconds on CPU\n"
          ]
        }
      ]
    }
  ]
}