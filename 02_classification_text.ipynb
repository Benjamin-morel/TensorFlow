{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Benjamin-morel/TensorFlow/blob/main/02_classification_text.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-HaWB3Owxi1"
      },
      "source": [
        "---\n",
        "\n",
        "\n",
        "# **Machine Learning Model: basic text classification**\n",
        "\n",
        "| | |\n",
        "|------|------|\n",
        "| Filename | 02_classification_test.ipynb |\n",
        "| Author(s) | Benjamin Morel (benjaminmorel27@gmail.com) |\n",
        "| Date | September 4, 2024 |\n",
        "| Aim(s) | Build, train and evaluate a neural network machine learning model that classifies movie reviews as positives or negatives. |\n",
        "| Dataset(s) | Stanford dataset [[1]](https://ai.stanford.edu/~amaas/data/sentiment/)|\n",
        "| Version | Python 3.12 - TensorFlow 2.17.0 |\n",
        "\n",
        "\n",
        "<br> **!!Read before running!!** <br>\n",
        "1. Fill in the inputs\n",
        "2. GPU execution recommended if `training_phase=\"Yes\"`.\n",
        "3. Run all and read comments.\n",
        "\n",
        "---\n",
        "\n",
        "#### **Motivation**\n",
        "\n",
        "AI is capable of managing and processing text made up of several thousand words, special characters and punctuation. In this Python code, the construction of the neural network and its optimization is similar to what has been done before. The main interest lies in the way the text is processed and broken down into elements.\n",
        "\n",
        "For this, the Stanford Sentiment Treebank (SST) database, composed of over 50,000 movie reviews on the Internet, is used to build a binary classification neural network. A film review with a rating below 4/10 will be classified as negative and with a rating above 7/10 as positive.\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GVXaEQPzZeq0"
      },
      "source": [
        "#### **0. Input section**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OVCvwvCvZgIJ"
      },
      "source": [
        "The model has already been trained: **parameters** (weights and biases) of each neuron are already known according to the base dataset. The user can choose to keep these parameters and **not retrain the model** (No), or he can decide to repeat the **training phase** (Yes). Using a pre-trained model saves time, computer resources and CO2 emissions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "Tla0F9fnZniD"
      },
      "outputs": [],
      "source": [
        "training_phase = 'No'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PNcpWfJ-9oED"
      },
      "source": [
        "---\n",
        "\n",
        "\n",
        "#### **1. Import libraries & prebuilt dataset**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_eE13ncCBllK"
      },
      "source": [
        "###### **1.1. Presentation of Python libraries**\n",
        "\n",
        "`os`: provides functions to interact with the operating system (manipulating files and directories, accessing system information...)\n",
        "\n",
        "`re`: performs complex searches and manipulations on strings (extracting substrings...)\n",
        "\n",
        "`shutil`: provides utilities for performing operations on files and directories (copying, modifying, deleting...)\n",
        "\n",
        "`string`: provides tools for handling and processing strings\n",
        "\n",
        "`numpy`: library for scientific computing\n",
        "\n",
        "`tensorflow`: builds and trains machine learning and deep learning models\n",
        "\n",
        "`matplotlib.pyplot`: creates graphs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "AYUJBo2iwkEH"
      },
      "outputs": [],
      "source": [
        "from os import path, listdir                                                # miscellaneous operating system interfaces\n",
        "from re import escape                                                       # regular expressions\n",
        "from shutil import rmtree                                                   # operations on files\n",
        "from string import punctuation                                              # string manipulation\n",
        "from numpy import shape, linalg, cos, sin, pi                               # scientific computing\n",
        "from tensorflow import constant, keras, strings, expand_dims, data, metrics # machine learning models\n",
        "from matplotlib.pyplot import subplots, title                               # graphing package"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2zcHbIgB3ql"
      },
      "source": [
        "###### **1.2. Which database is used?**\n",
        "\n",
        "The considered database is a version of the Stanford Sentiment Treebank (SST), a dataset created for sentiment analysis in movie reviews. It contains movie reviews labeled with sentiment (positive or negative) and is widely used to train and test sentiment analysis models. Movie reviews are contained into the compressed file `aclimdb`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "pZREb5FsxYCp"
      },
      "outputs": [],
      "source": [
        "url = \"https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\"\n",
        "\n",
        "dataset = keras.utils.get_file(\"aclImdb_v1\", url, extract=True, cache_dir='.', cache_subdir='')\n",
        "dataset_dir = path.join(path.dirname(dataset), 'aclImdb')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-rQAmrHV24_"
      },
      "source": [
        "###### **1.3. How data is organized within Stanford movie review database?**\n",
        "\n",
        "Once the file is extracted, the following structure is composed of 5 folders: `train`, `test`, `README`, `imdbEr.txt` and `imdb.vocab`. The following code line is used to check file name into the directory.\n",
        "\n",
        "*   `train`: contains movie reviews meant for training\n",
        "*   `test`: contains movie reviews meant for testing\n",
        "*   `README`: provides information about the dataset and how to use it\n",
        "*   `imdb.vocab` and `imdbEr.txt` contain additional information about errors, URL website and specific annotations\n",
        "\n",
        "Within both the `test` and `train` folders, there are two subfolders:\n",
        "\n",
        "*   `pos`: contains movie reviews with a positive sentiment (rating > 7/10)\n",
        "*   `unsup`: contains unlabeled movie reviews for unsupervised learning\n",
        "*   `neg`: contains movie reviews with a negative sentiment (rating < 4/10)\n",
        "\n",
        "Each text file in these subfolders represents a single movie review and contains the raw text of the review. They are cleaned to contain only raw text, without additional metadata."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yaYwjEYQAYJj",
        "outputId": "2e922285-43e9-4014-8644-6b137e310ce5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['train', 'imdb.vocab', 'test', 'README', 'imdbEr.txt']"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ],
      "source": [
        "listdir(dataset_dir) # check the file names in the aclImdb directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "wJLocve1DXls"
      },
      "outputs": [],
      "source": [
        "train_dir = path.join(dataset_dir, 'train') # path name of the \"train\" file in dataset_dir\n",
        "remove_dir = path.join(train_dir, 'unsup') # remove the folder with unlabeled reviews for unsupervised learning\n",
        "rmtree(remove_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i0TM938pDspy"
      },
      "source": [
        "###### **1.4. How data is submitted during the learning phase**\n",
        "\n",
        "A good practice for a machine learning experiment is to divide the dataset into 3 splits: `train`, `test` and `validation`. Two of them are already available. The validation set is created by using 20% of the training data set.\n",
        "\n",
        "The 3 subsets are organized in batches for multiple reasons: memory, parallel computation, fast calculation of gradients, standardize the processing of training, validation and test sets... For this, the TensorFlow function `text_dataset_from_directory` is used to randomly shuffle texts present in the train folder and then divide this shuffle to generate the training dataset (80%) and the validation dataset (20%). Finally, for each dataset, all the data is grouped into batches of 32 texts.\n",
        "\n",
        "The 3 subsets are stored in the data structures `tf.data.Dataset`. The data is not loaded into immediate memory, but generated when it is called up. The `show_text()` function displays an example of the text in the first batch of the data structure `tf.data.Dataset`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "JNMXUoFwPfWv"
      },
      "outputs": [],
      "source": [
        "def show_text(text_batch): # get the first text of the first batch\n",
        "  for text_batch, label_batch in text_batch: # navigate through the text batch\n",
        "      if label_batch.numpy()[0] == 0:\n",
        "        print(\"Here's an extract from a negative review:\")\n",
        "        print(text_batch.numpy()[0])\n",
        "      else:\n",
        "        print(\"Here's an extract from a positive review:\")\n",
        "        print(text_batch.numpy()[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5I8TejG3xtfj",
        "outputId": "918c7263-9f93-489b-8bac-17917c50810d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 25000 files belonging to 2 classes.\n",
            "Using 20000 files for training.\n",
            "Found 25000 files belonging to 2 classes.\n",
            "Using 5000 files for validation.\n",
            "Found 25000 files belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "batch_size = 32\n",
        "raw_train_ds = keras.utils.text_dataset_from_directory('aclImdb/train', batch_size=batch_size, validation_split=0.2, subset='training', shuffle=True, seed=42) # 625 batches of 32 texts for training set randomly chosen\n",
        "raw_val_ds = keras.utils.text_dataset_from_directory('aclImdb/train', batch_size=batch_size, validation_split=0.2, subset='validation', shuffle=True, seed=42) # 157 batches of 32 texts for validation set randomly chosen\n",
        "raw_test_ds = keras.utils.text_dataset_from_directory('aclImdb/test', batch_size=batch_size) # 782 batches of 32 texts for test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t2iM2eQ0wyVk",
        "outputId": "b9e93040-47b3-4a71-f01d-935b3c2b92ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here's an extract from a negative review:\n",
            "b'\"Pandemonium\" is a horror movie spoof that comes off more stupid than funny. Believe me when I tell you, I love comedies. Especially comedy spoofs. \"Airplane\", \"The Naked Gun\" trilogy, \"Blazing Saddles\", \"High Anxiety\", and \"Spaceballs\" are some of my favorite comedies that spoof a particular genre. \"Pandemonium\" is not up there with those films. Most of the scenes in this movie had me sitting there in stunned silence because the movie wasn\\'t all that funny. There are a few laughs in the film, but when you watch a comedy, you expect to laugh a lot more than a few times and that\\'s all this film has going for it. Geez, \"Scream\" had more laughs than this film and that was more of a horror film. How bizarre is that?<br /><br />*1/2 (out of four)'\n"
          ]
        }
      ],
      "source": [
        "first_batch_train = raw_train_ds.take(1) # get the first batch of the training text set\n",
        "show_text(first_batch_train) # show an example of movie review"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CpSzgX8abQGE"
      },
      "source": [
        "---\n",
        "\n",
        "\n",
        "#### **2. Pre-processing & reformating data**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pIzLCu7V6ubd"
      },
      "source": [
        "###### **2.1. How to switch from a verbal language to a machine language?**\n",
        "\n",
        "The textual data is pre-processed and converted before being used by the model. Three crucial phases are established:\n",
        "- standardization\n",
        "- tokenization\n",
        "- vectorization\n",
        "\n",
        "The first pre-processing step standardizes text data by replacing upper case with lower case letters, by removing html tags and punctuation characters. The variable `punctuation` contains all punctuation characters to be removed. Special characters such as those with accents are not present in English texts. A standardization function is declared and used to process training data in the same way as other data (avoid training/testing bias)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "spQOTob2ZULo",
        "outputId": "92d07772-9a37-419d-f472-30871a0f2acd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The punctuation characters eliminated are: \n",
            "  \n",
            " !\"\\#\\$%\\&'\\(\\)\\*\\+,\\-\\./:;<=>\\?@\\[\\\\\\]\\^_`\\{\\|\\}\\~\n"
          ]
        }
      ],
      "source": [
        "ponctuation = escape(punctuation)\n",
        "print(\"The punctuation characters eliminated are: \\n\", \" \\n\", ponctuation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "dUnwN3b6x55J"
      },
      "outputs": [],
      "source": [
        "def standardization(input_data): # standardization function\n",
        "  no_uppercases = strings.lower(input_data) # convert upper cases into lower cases...\n",
        "  no_html = strings.regex_replace(no_uppercases, '<br />', ' ') # ... then remove HTML strings and...\n",
        "  no_punctuation = strings.regex_replace(no_html, '[%s]' % ponctuation, '') # ... punctuation\n",
        "  return no_punctuation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IovmWK-uPcZA"
      },
      "source": [
        "The second pre-processing step is to transform strings of all texts into integers (=neural network inputs). Text elements are separated, recombined into **tokens** and finally converted into integers (vectorization step). The tokenization process is performed by the Keras layer `TextVectorization` which transforms a batch of strings into either a list of token indices. The 5,000 most frequently used tokens are kept and stored in a dictionary [[2]](https://ai.stanford.edu/~amaas/papers/wvSent_acl2011.pdf). This threshold is used to eliminate words that aren't often used or that don't evoke feelings, such as actor names.\n",
        "\n",
        "The dictionnary called **vocabulary** is built by using raw texts inputs of the training set (labels `y` are ignored)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "w5_uvCYKx8Co"
      },
      "outputs": [],
      "source": [
        "max_features = 5000 # maximum number of words (=tokens) to consider in the vocabulary.\n",
        "max_length = 500 # maximum number of words per review\n",
        "vectorize_layer = keras.layers.TextVectorization(standardize=standardization, max_tokens=max_features, output_sequence_length=max_length, output_mode='int') # transform strings into sequences of integers\n",
        "\n",
        "vectorize_layer.adapt(raw_train_ds.map(lambda x, y: x)) # vectorization layer to learn the vocabulary from the raw texts in the training dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4HNDvV0LJTE"
      },
      "source": [
        "###### **2.2. How do you visualize these transformations?**\n",
        "\n",
        "The first function `token_to_int` shows the transformation of text elements into integers. The second `int_to_token`is used to identify which token is associated with a given integer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GlardaNcYWqD",
        "outputId": "5bc23e23-8d02-41cd-9f70-caa79c4554e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Review before tokenization and vectorization: \n",
            " tf.Tensor(b'Silent Night, Deadly Night 5 is the very last of the series, and like part 4, it\\'s unrelated to the first three except by title and the fact that it\\'s a Christmas-themed horror flick.<br /><br />Except to the oblivious, there\\'s some obvious things going on here...Mickey Rooney plays a toymaker named Joe Petto and his creepy son\\'s name is Pino. Ring a bell, anyone? Now, a little boy named Derek heard a knock at the door one evening, and opened it to find a present on the doorstep for him. Even though it said \"don\\'t open till Christmas\", he begins to open it anyway but is stopped by his dad, who scolds him and sends him to bed, and opens the gift himself. Inside is a little red ball that sprouts Santa arms and a head, and proceeds to kill dad. Oops, maybe he should have left well-enough alone. Of course Derek is then traumatized by the incident since he watched it from the stairs, but he doesn\\'t grow up to be some killer Santa, he just stops talking.<br /><br />There\\'s a mysterious stranger lurking around, who seems very interested in the toys that Joe Petto makes. We even see him buying a bunch when Derek\\'s mom takes him to the store to find a gift for him to bring him out of his trauma. And what exactly is this guy doing? Well, we\\'re not sure but he does seem to be taking these toys apart to see what makes them tick. He does keep his landlord from evicting him by promising him to pay him in cash the next day and presents him with a \"Larry the Larvae\" toy for his kid, but of course \"Larry\" is not a good toy and gets out of the box in the car and of course, well, things aren\\'t pretty.<br /><br />Anyway, eventually what\\'s going on with Joe Petto and Pino is of course revealed, and as with the old story, Pino is not a \"real boy\". Pino is probably even more agitated and naughty because he suffers from \"Kenitalia\" (a smooth plastic crotch) so that could account for his evil ways. And the identity of the lurking stranger is revealed too, and there\\'s even kind of a happy ending of sorts. Whee.<br /><br />A step up from part 4, but not much of one. Again, Brian Yuzna is involved, and Screaming Mad George, so some decent special effects, but not enough to make this great. A few leftovers from part 4 are hanging around too, like Clint Howard and Neith Hunter, but that doesn\\'t really make any difference. Anyway, I now have seeing the whole series out of my system. Now if I could get some of it out of my brain. 4 out of 5.', shape=(), dtype=string)\n",
            " \n",
            "Review after tokenization and vectorization: \n",
            " tf.Tensor(\n",
            "[1287  313 2380  313  661    7    2   52  229    5    2  200    3   38\n",
            "  170  669   29    1    6    2   83  297  549   32  410    3    2  186\n",
            "   12   29    4    1  191  510  549    6    2    1  212   46  576  175\n",
            "  168   20    1    1  290    4    1  761  969    1    3   24  935 2271\n",
            "  393    7    1 1675    4 3747  250  148    4  112  436  761 3529  548\n",
            "    4 3633   31    2 1331   28 2096    3 2912    9    6  163    4 1006\n",
            "   20    2    1   15   85   53  147    9  292   89  959 2314  984   27\n",
            "  762    6  959    9  564   18    7 2140   32   24 1254   36    1   85\n",
            "    3 3298   85    6 1410    3 1936    2 3408  301  965    7    4  112\n",
            "  740 1977   12    1 2014 2772    3    4  428    3    1    6  512 1254\n",
            "    1  278   27  139   25  308    1  579    5  259 3529    7   92    1\n",
            "   32    2 3842  230   27  289    9   35    2    1   18   27  144 2166\n",
            "   56    6   26   46  466 2014   27   40 2745  657  212    4 1376 3002\n",
            "    1  183   36  180   52  920    8    2 4028   12  969    1  158   71\n",
            "   53   67   85 2754    4  734   51    1 1611  294   85    6    2 1164\n",
            "    6  163    4 3408   15   85    6  717   85   44    5   24    1    3\n",
            "   48  604    7   11  225  384   73   65   21  242   18   27  120  295\n",
            "    6   26  667  129 4028  948    6   67   48  158   93    1   27  120\n",
            "  372   24    1   35    1   85   32 2342   85    6 1008   85    8 2349\n",
            "    2  357  257    3 2391   85   16    4 2812    2    1 2904   15   24\n",
            "  554   18    5  259 2812    7   21    4   49 2904    3  201   44    5\n",
            "    2 1039    8    2  521    3    5  259   73  175  691  179  564  834\n",
            "  692  168   20   16  969    1    3    1    7    5  259 1960    3   14\n",
            "   16    2  161   63    1    7   21    4  145  436    1    7  235   53\n",
            "   50    1    3    1   84   27 2320   35    1    4 3621 3076    1   37\n",
            "   12   98 2620   15   24  437  760    3    2 2158    5    2    1 3002\n",
            "    7 1960   99    3  212   53  236    5    4  654  270    5 2656    1\n",
            "    4 1520   56   35  170  669   18   21   72    5   28  169 1597    1\n",
            "    7  565    3 1835 1084  722   37   46  529  306  300   18   21  187\n",
            "    6   96   11   86    4  166    1   35  170  669   23 2356  183   99\n",
            "   38 4172 2274    3    1 2291   18   12  144   62   96   97 1390  564\n",
            "   10  148   25  311    2  211  200   44    5   54 1432  148   45   10\n",
            "   98   75   46    5    9   44    5   54 1344  669   44    5  661    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0], shape=(500,), dtype=int64)\n"
          ]
        }
      ],
      "source": [
        "def token_to_int(raw_text):\n",
        "  raw_text = next(iter(raw_text))[0]\n",
        "  print(\"Review before tokenization and vectorization: \\n\", raw_text[0])\n",
        "  print(\" \")\n",
        "  text_vectorized = expand_dims(raw_text, -1) #\n",
        "  text_vectorized = vectorize_layer(text_vectorized)\n",
        "  print(\"Review after tokenization and vectorization: \\n\", text_vectorized[0])\n",
        "\n",
        "token_to_int(raw_train_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zvLRLjSODwsi",
        "outputId": "25b11336-5213-438f-c667-2fd945c37d7b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The integer 7 represent the token: is\n"
          ]
        }
      ],
      "source": [
        "def int_to_token(index):\n",
        "  token = vectorize_layer.get_vocabulary()[index]\n",
        "  print(\"The integer %d represent the token: %s\" %(index, token))\n",
        "\n",
        "int_to_token(7)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hDs5MOc7Usll"
      },
      "source": [
        "---\n",
        "\n",
        "\n",
        "#### **3. Model and training**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eVadUbUyOSpz"
      },
      "source": [
        "###### **3.1. How to configure the datasets for performance?**\n",
        "\n",
        "During the model training phase, the duration represents the time required to open the data file, read it and train with it. By default, these steps are performed one at a time. With a prefetch method, the model opens the data file, then executes a training step `s` and loads the data for step `s+1` at the same time. Loading the batch in the background during the training phase enables more efficient use of available computing resources, avoiding the risk of a \"bottleneck\" where computation (GPU) is limited by the speed at which data is supplied (I/O).\n",
        "\n",
        "The overlapping of these steps is ensured by the `prefetch()` function, where the size of the prefetch buffer is automatically set by TensorFlow via the parameter `AUTOTUNE`.\n",
        "\n",
        "The function `cache()` temporarily stores transformed data of a batch (standardization + tokenization + vectorization) in the RAM memory (12.7 GB RAM for a Google configuration). This method saves a significant amount of time since complex transformations applied to the texts are only performed during the first epoch and re-used for the others."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "Y5W-pc4I8Wk3"
      },
      "outputs": [],
      "source": [
        "AUTOTUNE = data.AUTOTUNE # prefetch buffer size parameter\n",
        "\n",
        "raw_train_ds = raw_train_ds.cache().prefetch(buffer_size=AUTOTUNE) # store raw_train_ds temporarily in the RAM + load the next batch in background with a prefetch buffer size computed by AUTOTUNE\n",
        "raw_val_ds = raw_val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "raw_test_ds = raw_test_ds.cache().prefetch(buffer_size=AUTOTUNE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQnGHKrYOfhQ"
      },
      "source": [
        "###### **3.2. What is a neural network formed of?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3z7bRecdVwtG"
      },
      "source": [
        "**Pre-processing layer** `vectorize_layer`:\n",
        "* **Inputs:** a text vector of dimension `batch_size` (=32).\n",
        "* **Outputs:** an integer 2D tensor of dimensions (`batch_size`, `max_length`) (= (32, 500)).\n",
        "* **Comments:** each text of the batch of 32 elements is truncated to the 501st (= `max_length`) and then an integer is associated with each of the 5,000 most frequently used words (= `max_features`) in the text dataset. The word index is referenced in a dictionary, called *vocabulary*, and is common to all texts in the dataset. If the text is less than 500 words long (= `max_length`), the output tensor is padded with zeros.\n",
        "\n",
        "<br>**Embedding layer** `Embedding`: <br>\n",
        "* **Inputs:** an integer 2D tensor of dimensions (`batch_size`, `max_length`) (= (32, 500)).\n",
        "* **Outputs:** a float 3D tensor of dimensions (`batch_size`, `max_length`, `embedding_dim`) (=(32, 500, 16)).\n",
        "* **Comments:** The Keras embedding layer manages its own dictionary, in which each word is linked to a dense vector of dimension `embedding_dim` (=16). The layer returns a 16-float vector for each element of the 2D tensor input. The Embedding dictionnary is modified/adapted during the learning phase since the 16-components of an embedding vecteor are considered as weights and modified by an optimization algorithm.\n",
        "\n",
        "<br>**Pooling layer** `GlobalAveragePooling1D`: <br>\n",
        "* **Inputs:** a float 3D tensor of dimensions (`batch_size`, `max_length`, `embedding_dim`) (=(32, 500, 16)).\n",
        "* **Outputs:** a float 2D tensor of dimensions (`batch_size`, `embedding_dim`) (=(32, 16)).\n",
        "* **Comments:** This layer will average all the 16-dense vectors of a text. This reduction loses the word order, but partially integrates the meaning of the text.\n",
        "\n",
        "<br>**Fully-connected layer** `Dense`: <br>\n",
        "* **Inputs:** a float 2D tensor of dimensions (`batch_size`, `embedding_dim`) (=(32, 16)).\n",
        "* **Outputs:** maximum 32 scalars between 0 (=negative sentiment) and 1 (=positive sentiment).\n",
        "* **Comments:** if this scalar is close to 0.5, the model cannot conclude with certainty.  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "ZVy751wzln8H"
      },
      "outputs": [],
      "source": [
        "def create_model():\n",
        "  embedding_dim = 16\n",
        "  model = keras.Sequential()\n",
        "  model.add(vectorize_layer) # pre-processing layer (standardization + tokenization + vectorization)\n",
        "  model.add(keras.layers.Embedding(input_dim = max_features, output_dim = embedding_dim))\n",
        "  model.add(keras.layers.Dropout(0.2))\n",
        "  model.add(keras.layers.GlobalAveragePooling1D())\n",
        "  model.add(keras.layers.Dropout(0.2))\n",
        "  model.add(keras.layers.Dense(1, activation='sigmoid')) # 1 output: propbability\n",
        "\n",
        "  model.compile(loss=keras.losses.BinaryCrossentropy(), optimizer='adam', metrics=[metrics.BinaryAccuracy()])\n",
        "\n",
        "  return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wnY6ZDN9OsPe"
      },
      "source": [
        "###### **3.3. How to train the model?**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "akEY74O-4mGl"
      },
      "outputs": [],
      "source": [
        "if training_phase == \"Yes\":\n",
        "  checkpoint_path = \"02_classification_text.weights.h5\"\n",
        "  cp_callback = keras.callbacks.ModelCheckpoint(filepath=checkpoint_path, save_weights_only=True, verbose=0)\n",
        "  stop_early = keras.callbacks.EarlyStopping(monitor='val_binary_accuracy', patience=10, restore_best_weights=True, min_delta=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "MZ-W38br25go"
      },
      "outputs": [],
      "source": [
        "model = create_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "urPAjUL-ydCq",
        "outputId": "a62cbec3-a90b-4969-ae36-fb29772fc817"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'TensorFlow'...\n",
            "remote: Enumerating objects: 111, done.\u001b[K\n",
            "remote: Counting objects: 100% (111/111), done.\u001b[K\n",
            "remote: Compressing objects: 100% (110/110), done.\u001b[K\n",
            "remote: Total 111 (delta 47), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (111/111), 18.01 MiB | 15.28 MiB/s, done.\n",
            "Resolving deltas: 100% (47/47), done.\n"
          ]
        }
      ],
      "source": [
        "if training_phase == \"Yes\":\n",
        "  history = model.fit(raw_train_ds, validation_data=raw_val_ds, epochs=100, callbacks=[stop_early, cp_callback], verbose=0)\n",
        "  val_acc_per_epoch = history.history['val_binary_accuracy'] # best val_binary_accuracy achived at epoch 32\n",
        "  best_epoch = val_acc_per_epoch.index(max(val_acc_per_epoch)) + 1\n",
        "  print('Best epoch: %d' % (best_epoch))\n",
        "else:\n",
        "  !git clone https://github.com/Benjamin-morel/TensorFlow.git # go to the Github repertory TensorFlow and clone it\n",
        "  model.fit(raw_train_ds, validation_data=raw_val_ds, epochs=1, verbose=0)\n",
        "  model.load_weights(\"TensorFlow/02_classification_text.weights.h5\") # import weights from the cloned repertory\n",
        "  !rm -rf TensorFlow/ # delete the cloned repertory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "iXkzAUtK6Kg4"
      },
      "outputs": [],
      "source": [
        "def show_evolution(history):\n",
        "  history_dict = history.history\n",
        "  acc_train = history_dict['binary_accuracy']\n",
        "  acc_val = history_dict['val_binary_accuracy']\n",
        "  epochs = range(1, len(acc_train) + 1)\n",
        "\n",
        "  fig, ax = subplots(figsize=(8, 6))\n",
        "  ax.plot(epochs, acc_train, label='Training', color='blue')\n",
        "  ax.plot(epochs, acc_val, label='Validation', color='orange')\n",
        "  ax.legend(loc='upper left', bbox_to_anchor=(0.02, 0.98), frameon=True, facecolor='white', edgecolor='black', fontsize=10)\n",
        "  ax.set_xlabel('Epochs', fontsize=12), ax.set_ylabel('Binary Accuracy', fontsize=12)\n",
        "  ax.grid(True, linestyle='--', alpha=0.6)\n",
        "  fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "awd3_-nj6DQZ"
      },
      "outputs": [],
      "source": [
        "if training_phase == 'Yes':\n",
        "  show_evolution(history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6VZ-HWnoU19c"
      },
      "source": [
        "---\n",
        "\n",
        "\n",
        "#### **4. Evaluation and prediction**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "SgYqxc_pyhX-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9df3ee01-0925-4ca0-bc33-a1280f8351e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - binary_accuracy: 0.8782 - loss: 0.3054\n",
            "\n",
            "  88.024% of the test set is corretly predicted\n",
            "  \n"
          ]
        }
      ],
      "source": [
        "loss, accuracy = model.evaluate(raw_test_ds)\n",
        "\n",
        "print(f\"\"\"\n",
        "  {round(100*accuracy, 3)}% of the test set is corretly predicted\n",
        "  \"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jPO0X7THurRd"
      },
      "source": [
        "It is now possible to use the trained model to recognize the sentiment of the author of a film review. Write your own review in the next section and check the model's prediction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "EqhYu-ySJa5a"
      },
      "outputs": [],
      "source": [
        "my_review = [\"This movie was terrible and boring. Most of scenes were violents and useless.\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "h1pa8S_v6VEJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1fb86a5a-f6b2-4b8a-83b3-ba3f271c4090"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step\n",
            "The movie looks pretty bad. (score model:  0.1 )\n"
          ]
        }
      ],
      "source": [
        "examples = constant(my_review)\n",
        "\n",
        "prediction = model.predict(examples)\n",
        "if prediction < 0.5:\n",
        "  print(\"The movie looks pretty bad. (score model: \", round(prediction[0][0], 1), \")\")\n",
        "else:\n",
        "  print(\"Great movie, go see it in the cinema! (score model: \", round(prediction[0][0], 1), \")\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HmAA9z068MHx"
      },
      "source": [
        "---\n",
        "\n",
        "\n",
        "#### **5. Let's explore the embedding dictionnary**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G3ESqKNN83Fv"
      },
      "source": [
        "For the embedding dictionnary exploration, the 16 values from the 5000 vectors are extracted. As a reminder, these vectors are the weights of the Embedding layer and can be retrieved using the function `get_weights`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "Aj9S7Sg_PjHS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d14c3a79-8d74-4f5d-b923-eadb503c4d11"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The dictionnary size is equal to: (5000, 16)\n"
          ]
        }
      ],
      "source": [
        "embeddings_vector = model.layers[1].get_weights()[0] # embedding layer is the second layer of the model\n",
        "print(\"The dictionnary size is equal to:\",(shape(embeddings_vector)))\n",
        "dictionary_embedding = {vectorize_layer.get_vocabulary()[i]:embeddings_vector[i] for i in range(max_features)}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-o_Bnkn9khQ"
      },
      "source": [
        "Then, it's essential to associate a word with its vector given by the embedding dictionary. To do this, another dictionary `word_to_embeddings_vector` is built, containing the 16 real values of the dense vector's components for the 5000 most frequently used words. An example is given by entering the word \"good\" in the dictionary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "id": "ozcHQsAQRKkL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b6af278-65db-4cc1-b5bc-a3acbb54289c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.74045223,  0.72797775, -0.81483996,  0.7455467 , -0.5748099 ,\n",
              "       -0.72785854, -0.6728519 ,  0.708197  ,  0.65778595,  0.6499005 ,\n",
              "       -0.7387788 ,  0.7020209 , -0.7547246 , -0.67552066, -0.7161834 ,\n",
              "       -0.79400253], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ],
      "source": [
        "dictionary_embedding[\"good\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "id": "CfJN4l0_RX_p"
      },
      "outputs": [],
      "source": [
        "def get_distance(token1, token2):\n",
        "  p1 = dictionary_embedding[token1] # position of token 1 in the 16 dimensions embedding space\n",
        "  p2 = dictionary_embedding[token2] # position of token 2\n",
        "  distance = np.linalg.norm(p2-p1) # norm computation\n",
        "  return distance\n",
        "\n",
        "def get_synomym(token, n):\n",
        "  p1 = dictionary_embedding[token]\n",
        "  candidate_list = {} # stores n synonyms\n",
        "  for i in range(1, 1000):\n",
        "    token_candidate = vectorize_layer.get_vocabulary()[i]\n",
        "    candidate_list[token_candidate] = get_distance(token, token_candidate)\n",
        "\n",
        "  sorted_items = sorted(candidate_list.items(), key=lambda item: item[1])\n",
        "\n",
        "  synonym_list = sorted_items[1:n+1]\n",
        "  words = [item[0] for item in synonym_list]\n",
        "  distance = [item[1] for item in synonym_list]\n",
        "\n",
        "  fig, ax = subplots(figsize=(6, 6))\n",
        "\n",
        "  for i in range(len(distance)):\n",
        "      x = distance[i] * cos((i + 1) * 2*pi / len(distance))\n",
        "      y = distance[i] * sin((i + 1) * 2*pi / len(distance))\n",
        "\n",
        "      ax.scatter(0, 0, color='red', s=50)\n",
        "      ax.text(0, 0.1, word, fontsize=12, color='red', ha='center', va='center')\n",
        "      ax.scatter(x, y, color='black', s=15)\n",
        "      ax.text(x, y+0.1, words[i], fontsize=10, color='black', ha='center', va='center')\n",
        "\n",
        "  ax.set_xlim(-1.1*max(distance), 1.1*max(distance))\n",
        "  ax.set_ylim(-1.1*max(distance), 1.1*max(distance))\n",
        "  ax.set_aspect('equal'), ax.axis('off')\n",
        "  title(\"Neighbors of %s\" %word, fontsize=16)\n",
        "  fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "id": "0EiVWW81SevD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "785b8b31-0131-4493-8f11-d0c7d5215da1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20.256641"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ],
      "source": [
        "get_distance(\"nice\", \"terrible\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "id": "5b-b8irFSxTb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 523
        },
        "outputId": "fd8ffc0c-d142-4fbe-e2c9-94e5b327af25"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "word = \"fun\" # which word to seek neighbors for?\n",
        "nb = 10 # how many?\n",
        "get_synomym(word, nb)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP4LCdohwnRAgA1AenAnwxs",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}