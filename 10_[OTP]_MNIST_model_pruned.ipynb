{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPhMWpQ2sWfdwAH5QSm4PpB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Benjamin-morel/TensorFlow/blob/main/10_%5BOTP%5D_MNIST_model_pruned.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "\n",
        "# **ML Model: compress an image classification model**\n",
        "\n",
        "| | |\n",
        "|------|------|\n",
        "| Filename | 10_[OTP]_MNIST_model_pruned.ipynb |\n",
        "| Author(s) | Benjamin Morel (benjaminmorel27@gmail.com) |\n",
        "| Date | February 18, 2025 |\n",
        "| Aim(s) | compress and quantize a model from a pruning method |\n",
        "| Dataset(s) | - |\n",
        "| Version | Python 3.10.12 - TensorFlow 2.17.1 |\n",
        "\n",
        "\n",
        "<br> **!!Read before running!!** <br>\n",
        "1. Fill in the inputs\n",
        "2. CPU execution is enough\n",
        "3. Run all and read comments\n",
        "\n",
        "---\n",
        "\n",
        "#### **Motivation**\n",
        "\n",
        "#### **Outline**\n"
      ],
      "metadata": {
        "id": "v_VGe7_RaMgn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## **1. Python librairies & display utilities**"
      ],
      "metadata": {
        "id": "EX4YWSozbFi2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 1.1. Python librairies [RUN ME]\n",
        "\n",
        "! pip install -q tensorflow-model-optimization\n",
        "\n",
        "\"\"\"math\"\"\"\n",
        "import numpy as np\n",
        "\n",
        "\"\"\"file opening\"\"\"\n",
        "import os\n",
        "import tempfile\n",
        "import zipfile\n",
        "\n",
        "\"\"\"data\"\"\"\n",
        "import pandas as pd\n",
        "\n",
        "\"\"\"ML models\"\"\"\n",
        "import tensorflow as tf\n",
        "\n",
        "\"\"\"optimization package\"\"\"\n",
        "import tensorflow_model_optimization as tfmot\n",
        "from tensorflow_model_optimization.python.core.keras.compat import keras\n",
        "\n",
        "\"\"\"performances\"\"\"\n",
        "from time import time\n",
        "start = time()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MB_mAsO3bNF9",
        "outputId": "f98f95bb-7e8b-43a2-e6cb-62806fbde32e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/242.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.6/242.5 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.5/242.5 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "\n",
        "## **2. Model creation and training**"
      ],
      "metadata": {
        "id": "N1i89dMtcLmG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1. Data acquisition"
      ],
      "metadata": {
        "id": "87EyXDhkiU7G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_data_MNIST():\n",
        "  mnist = tf.keras.datasets.mnist # import MNIST build-in dataset\n",
        "  (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "  return x_train, y_train, x_test, y_test"
      ],
      "metadata": {
        "id": "ZV4Sl1nbcMQi"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, y_train, x_test, y_test = get_data_MNIST()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0 # normalization"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZVyL_cnbcmts",
        "outputId": "aea53331-afbd-4c9b-ec77-4677c8f28559"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2. Model architecture"
      ],
      "metadata": {
        "id": "uGpSdsihiZrV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model():\n",
        "  DR = 0.2 # according to [4]\n",
        "  model = keras.Sequential([\n",
        "      keras.layers.Flatten(input_shape=(28, 28)),\n",
        "      keras.layers.Dense(128, activation='relu'),\n",
        "      keras.layers.Dropout(DR),\n",
        "      keras.layers.Dense(10),\n",
        "      keras.layers.Softmax()\n",
        "      ])\n",
        "\n",
        "  loss_fn = keras.losses.SparseCategoricalCrossentropy(from_logits=False) # loss function (outputs are not logits but proba)\n",
        "  model.compile(optimizer=\"sgd\", loss=loss_fn, metrics=['accuracy'])\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "zsqSw-FAcqjQ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.3. Model training"
      ],
      "metadata": {
        "id": "U8VFe02kichB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, features, labels, **kwargs):\n",
        "  kwargs.setdefault(\"epochs\", 5)\n",
        "  kwargs.setdefault(\"validation_split\", 0)\n",
        "  kwargs.setdefault(\"batch_size\", 32)\n",
        "  kwargs.setdefault(\"callbacks\", None)\n",
        "  kwargs.setdefault(\"verbose\", 2)\n",
        "  log = model.fit(features, labels, **kwargs)\n",
        "\n",
        "  return log.history[\"loss\"], log.history[\"accuracy\"], log.history[\"val_loss\"], log.history[\"val_accuracy\"]"
      ],
      "metadata": {
        "id": "IrIseumTcts4"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 15\n",
        "validation_split = 0.2\n",
        "batch_size = 64\n",
        "\n",
        "model_MNIST = create_model()\n",
        "history = train_model(model_MNIST, x_train, y_train, validation_split=validation_split, epochs=epochs, batch_size=batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E35iVcWzcvMt",
        "outputId": "8716378b-336a-41e8-aaca-b154c0d04f1e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "750/750 - 8s - loss: 1.0366 - accuracy: 0.7218 - val_loss: 0.5132 - val_accuracy: 0.8786 - 8s/epoch - 10ms/step\n",
            "Epoch 2/15\n",
            "750/750 - 5s - loss: 0.5278 - accuracy: 0.8540 - val_loss: 0.3838 - val_accuracy: 0.9011 - 5s/epoch - 7ms/step\n",
            "Epoch 3/15\n",
            "750/750 - 6s - loss: 0.4355 - accuracy: 0.8767 - val_loss: 0.3364 - val_accuracy: 0.9085 - 6s/epoch - 8ms/step\n",
            "Epoch 4/15\n",
            "750/750 - 5s - loss: 0.3892 - accuracy: 0.8886 - val_loss: 0.3096 - val_accuracy: 0.9138 - 5s/epoch - 7ms/step\n",
            "Epoch 5/15\n",
            "750/750 - 5s - loss: 0.3602 - accuracy: 0.8980 - val_loss: 0.2873 - val_accuracy: 0.9202 - 5s/epoch - 7ms/step\n",
            "Epoch 6/15\n",
            "750/750 - 7s - loss: 0.3373 - accuracy: 0.9038 - val_loss: 0.2715 - val_accuracy: 0.9250 - 7s/epoch - 9ms/step\n",
            "Epoch 7/15\n",
            "750/750 - 4s - loss: 0.3154 - accuracy: 0.9092 - val_loss: 0.2572 - val_accuracy: 0.9298 - 4s/epoch - 5ms/step\n",
            "Epoch 8/15\n",
            "750/750 - 4s - loss: 0.3004 - accuracy: 0.9152 - val_loss: 0.2462 - val_accuracy: 0.9325 - 4s/epoch - 5ms/step\n",
            "Epoch 9/15\n",
            "750/750 - 4s - loss: 0.2868 - accuracy: 0.9192 - val_loss: 0.2368 - val_accuracy: 0.9352 - 4s/epoch - 5ms/step\n",
            "Epoch 10/15\n",
            "750/750 - 3s - loss: 0.2759 - accuracy: 0.9220 - val_loss: 0.2278 - val_accuracy: 0.9372 - 3s/epoch - 4ms/step\n",
            "Epoch 11/15\n",
            "750/750 - 3s - loss: 0.2643 - accuracy: 0.9252 - val_loss: 0.2197 - val_accuracy: 0.9401 - 3s/epoch - 4ms/step\n",
            "Epoch 12/15\n",
            "750/750 - 3s - loss: 0.2558 - accuracy: 0.9275 - val_loss: 0.2122 - val_accuracy: 0.9418 - 3s/epoch - 4ms/step\n",
            "Epoch 13/15\n",
            "750/750 - 4s - loss: 0.2471 - accuracy: 0.9302 - val_loss: 0.2059 - val_accuracy: 0.9434 - 4s/epoch - 5ms/step\n",
            "Epoch 14/15\n",
            "750/750 - 3s - loss: 0.2399 - accuracy: 0.9324 - val_loss: 0.2001 - val_accuracy: 0.9458 - 3s/epoch - 4ms/step\n",
            "Epoch 15/15\n",
            "750/750 - 3s - loss: 0.2330 - accuracy: 0.9343 - val_loss: 0.1945 - val_accuracy: 0.9473 - 3s/epoch - 4ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.4. Evaluation and saving"
      ],
      "metadata": {
        "id": "a1WF-JAPie4K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, features, labels):\n",
        "  start_interference = time()\n",
        "  loss, accuracy = model.evaluate(features, labels, verbose=0)\n",
        "  interference_time = time()-start_interference\n",
        "  print(\"Test loss value %0.1f \\nTest accuracy: %0.1f %%\" %(loss, 100*accuracy))\n",
        "  return accuracy, interference_time/len(features)"
      ],
      "metadata": {
        "id": "LtiEbq2khMBa"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_model(model, path):\n",
        "  keras.models.save_model(model, path)\n",
        "  print(\"Model correcty saved\")"
      ],
      "metadata": {
        "id": "7KLxfrrphtzO"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "initial_accuracy, initiale_time_interf = evaluate_model(model_MNIST, x_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sLsLJbk8h4sq",
        "outputId": "22aa2db9-8e26-42e7-8332-048a3451bcd9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss value 0.2 \n",
            "Test accuracy: 94.5 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path='10_MNIST_model_pruned_initial.keras'\n",
        "save_model(model_MNIST, path)\n",
        "initial_size = os.path.getsize(path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "45DCAZIDh9y_",
        "outputId": "3707839a-77fb-4fa3-a7b2-f725c92737df"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model correcty saved\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "\n",
        "## **3. Fine-tune pre-trained model with pruning**"
      ],
      "metadata": {
        "id": "R8ndTO7XiMgi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_pruned_model(initial_model, end_step):\n",
        "  prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
        "\n",
        "  pruning_params = {\n",
        "      'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.50,\n",
        "                                                               final_sparsity=0.80,\n",
        "                                                               begin_step=0,\n",
        "                                                               end_step=end_step)\n",
        "  }\n",
        "\n",
        "  model_for_pruning = prune_low_magnitude(model_MNIST, **pruning_params)\n",
        "\n",
        "  model_for_pruning.compile(optimizer='sgd',\n",
        "              loss=keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "  return model_for_pruning"
      ],
      "metadata": {
        "id": "2vyiFQdwmlkl"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_images = x_train.shape[0] * (1-validation_split)\n",
        "end_step = np.ceil(num_images / batch_size).astype(np.int32) * epochs\n",
        "\n",
        "model_for_pruning = create_pruned_model(model_MNIST, end_step)"
      ],
      "metadata": {
        "id": "6YYQnBbNd7V8"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logdir = tempfile.mkdtemp()\n",
        "\n",
        "callbacks = [\n",
        "  tfmot.sparsity.keras.UpdatePruningStep(),\n",
        "  tfmot.sparsity.keras.PruningSummaries(log_dir=logdir),\n",
        "]"
      ],
      "metadata": {
        "id": "U1Mn7Q60eUQm"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 5\n",
        "history_pruned = train_model(model_for_pruning, x_train, y_train, validation_split=validation_split, epochs=epochs, batch_size=batch_size, callbacks=callbacks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JynQfLckjDS5",
        "outputId": "f119623a-1dd0-45e0-bac5-e3ece51a937b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "750/750 - 7s - loss: 0.2555 - accuracy: 0.9305 - val_loss: 0.2097 - val_accuracy: 0.9438 - 7s/epoch - 9ms/step\n",
            "Epoch 2/5\n",
            "750/750 - 3s - loss: 0.2548 - accuracy: 0.9289 - val_loss: 0.2104 - val_accuracy: 0.9431 - 3s/epoch - 5ms/step\n",
            "Epoch 3/5\n",
            "750/750 - 4s - loss: 0.2585 - accuracy: 0.9280 - val_loss: 0.2092 - val_accuracy: 0.9458 - 4s/epoch - 6ms/step\n",
            "Epoch 4/5\n",
            "750/750 - 4s - loss: 0.2583 - accuracy: 0.9293 - val_loss: 0.2104 - val_accuracy: 0.9462 - 4s/epoch - 5ms/step\n",
            "Epoch 5/5\n",
            "750/750 - 3s - loss: 0.2608 - accuracy: 0.9278 - val_loss: 0.2127 - val_accuracy: 0.9437 - 3s/epoch - 4ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pruned_accuracy, pruned_time_interf = evaluate_model(model_for_pruning, x_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lz6DQf30jiO6",
        "outputId": "78b2eec6-bb81-451a-9d47-17067a693252"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss value 0.2 \n",
            "Test accuracy: 94.4 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_for_export = tfmot.sparsity.keras.strip_pruning(model_for_pruning)\n",
        "\n",
        "path='10_MNIST_model_pruned.keras'\n",
        "save_model(model_for_export, path)\n",
        "pruned_size = os.path.getsize(path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NZxOkZZ4jxC8",
        "outputId": "f54c1b2c-e448-4f12-c149-7a489b7fc09e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model correcty saved\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "\n",
        "## **4. Quantization**"
      ],
      "metadata": {
        "id": "yioQ4Qxk_JfN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "quantized_model = tfmot.quantization.keras.quantize_model(model_MNIST)\n"
      ],
      "metadata": {
        "id": "vVknK6csJs48"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "quantized_model.compile(optimizer='sgd',\n",
        "              loss=keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "epochs = 1\n",
        "history_quantized = train_model(quantized_model, x_train, y_train, validation_split=validation_split, epochs=epochs, batch_size=batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4b2AFRpJzYr",
        "outputId": "8ff03ecc-7e08-49a1-abaf-b25c2e9c5840"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "750/750 - 4s - loss: 0.2589 - accuracy: 0.9292 - val_loss: 0.1991 - val_accuracy: 0.9470 - 4s/epoch - 6ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(quantized_model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "\n",
        "quantized_tflite_model = converter.convert()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "izPMtiSX1VTS",
        "outputId": "1c0366c8-03e5-45b3-d6f6-96629e6891e1"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/tensorflow/lite/python/convert.py:997: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(interpreter):\n",
        "  input_index = interpreter.get_input_details()[0][\"index\"]\n",
        "  output_index = interpreter.get_output_details()[0][\"index\"]\n",
        "\n",
        "  # Run predictions on every image in the \"test\" dataset.\n",
        "  prediction_digits = []\n",
        "  start_interference = time()\n",
        "  for i, test_image in enumerate(x_test):\n",
        "    if i % 1000 == 0:\n",
        "      print('Evaluated on {n} results so far.'.format(n=i))\n",
        "    # Pre-processing: add batch dimension and convert to float32 to match with\n",
        "    # the model's input data format.\n",
        "    test_image = np.expand_dims(test_image, axis=0).astype(np.float32)\n",
        "    interpreter.set_tensor(input_index, test_image)\n",
        "\n",
        "    # Run inference.\n",
        "    interpreter.invoke()\n",
        "\n",
        "    # Post-processing: remove batch dimension and find the digit with highest\n",
        "    # probability.\n",
        "    output = interpreter.tensor(output_index)\n",
        "    digit = np.argmax(output()[0])\n",
        "    prediction_digits.append(digit)\n",
        "\n",
        "  print('\\n')\n",
        "  # Compare prediction results with ground truth labels to calculate accuracy.\n",
        "  prediction_digits = np.array(prediction_digits)\n",
        "  accuracy = (prediction_digits == y_test).mean()\n",
        "  interference_time = time()-start_interference\n",
        "\n",
        "  return accuracy, interference_time/len(x_test)"
      ],
      "metadata": {
        "id": "vwJjBNJJ1XZO"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "interpreter = tf.lite.Interpreter(model_content=quantized_tflite_model)\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "quantized_accuracy, quantized_time_interf = evaluate_model(interpreter)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T_x3Q2vu1ZSA",
        "outputId": "217fce1f-e4b6-4f34-be2e-620770f4aabf"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluated on 0 results so far.\n",
            "Evaluated on 1000 results so far.\n",
            "Evaluated on 2000 results so far.\n",
            "Evaluated on 3000 results so far.\n",
            "Evaluated on 4000 results so far.\n",
            "Evaluated on 5000 results so far.\n",
            "Evaluated on 6000 results so far.\n",
            "Evaluated on 7000 results so far.\n",
            "Evaluated on 8000 results so far.\n",
            "Evaluated on 9000 results so far.\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path='10_MNIST_model_pruned_quantized.keras'\n",
        "\n",
        "with open(path, 'wb') as f:\n",
        "  f.write(quantized_tflite_model)\n",
        "  f.close()\n",
        "\n",
        "quantized_size = os.path.getsize(path)"
      ],
      "metadata": {
        "id": "m7-rnFWO1a_z"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "\n",
        "## **5. Confrontation**"
      ],
      "metadata": {
        "id": "fX9ITfpe1dAi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_comparison(size_initial, size_pruned, size_quantized, acc_initial, acc_pruned, acc_quantized, time_initial, time_pruned, time_quantized):\n",
        "  df = pd.DataFrame(columns=[\"model\", \"size\", \"accuracy\", \"time for interference\"])\n",
        "  df.loc[0] = ['', \"[bytes]\", \"[%]\", \"[ms]\"]\n",
        "  df.loc[1] = ['initial', \"%.0f\" % size_initial, \"%.1f\" % acc_initial, \"%.3f\" % time_initial]\n",
        "  df.loc[2] = ['pruned', \"%.0f\" % size_pruned, \"%.1f\" % acc_pruned, \"%.3f\" % time_pruned]\n",
        "  df.loc[3] = ['quantized', \"%.0f\" % size_quantized, \"%.1f\" % acc_quantized, \"%.3f\" % time_quantized]\n",
        "  return print(df)\n",
        "\n",
        "plot_comparison(initial_size, pruned_size, quantized_size, 100*initial_accuracy, 100*pruned_accuracy, 100*quantized_accuracy, 1000*initiale_time_interf, 1000*pruned_time_interf, 1000*quantized_time_interf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b3BVinBE1eB7",
        "outputId": "4b0efaae-0467-4499-814e-5c7c956996ca"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       model     size accuracy time for interference\n",
            "0             [bytes]      [%]                  [ms]\n",
            "1    initial   840351     94.5                 0.077\n",
            "2     pruned   423122     94.4                 0.077\n",
            "3  quantized   105064     94.7                 0.020\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Notebook run in %.1f seconds on %s\" % ((time() - start), tf.config.list_physical_devices(device_type=None)[-1][-1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NdkghpqJ1iYi",
        "outputId": "cdfabb5d-6bc7-4787-a43e-c020086be759"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Notebook run in 105.5 seconds on CPU\n"
          ]
        }
      ]
    }
  ]
}